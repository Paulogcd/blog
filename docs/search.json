[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Articles",
    "section": "",
    "text": "Linear Regressions with Julia\n\n\n\n\n\n\njulia\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nJun 22, 2024\n\n\nPaulo Gugelmo Cavalheiro Dias\n\n\n\n\n\n\n\n\n\n\n\n\nPurpose statement\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMay 16, 2024\n\n\nPaulo Gugelmo Cavalheiro Dias\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/1_regressions_julia/index.html",
    "href": "posts/1_regressions_julia/index.html",
    "title": "Linear Regressions with Julia",
    "section": "",
    "text": "The first time I heard about Julia was a few months ago, in an introductory class to programming. Since then, I have come to know a bit more about the reputation of the language, supposely very efficient and especially suited for scientific computations.\nIn this article, I will try to perform some basic linear regressions with Julia and to plot them."
  },
  {
    "objectID": "posts/1_regressions_julia/index.html#simple-linear-regression",
    "href": "posts/1_regressions_julia/index.html#simple-linear-regression",
    "title": "Linear Regressions with Julia",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nHere, let us try to explain one continuous variable by another continuous variable.\nFirst, those are the packages we are going to use :\n\nusing Plots\nusing GLM\n\n\nThe Plots package seems to be the most general package to plot data with Julia. It is a simple interface to several underlying plotting packages, like gr or plotly. In this sense, it allows to easily switch between different frameworks that have different features, while keeping the same syntax.\nThe GLM package seems to be the main package for Generalized Linear Models (GLM) with Julia. It will be useful in the computation of our simple and multinomial linear models.\n\nNow, let us generate some data :\n\nx = range(0, 1, length=100)\n# Generate data : \ny = rand(100) .* x\n\n# Check the data :\nsize(y)\n\n(100,)\n\n\n\nThe function range() in Julia allows to create an array with a starting and an ending value. Although having similar properties than vectors, arrays created with the range() function have the “Range” type (or StepRangeLen to be exact). Here, I just initialise the x array to compute an easy to use y vector.\nThe function rand() in Julia allows to randomly generate numbers. The default settings of the function make it so that the drawn data is of type Float64 between \\(0\\) and \\(1\\). Its argument, set to the value of \\(100\\), indicates the number of random values that are to be drawn. Therefore, rand(100) returns a vector of 100 Float64 numbers.\nThe .* function is a vectorized multiplication. In Julia, adding a dot . before a mathematical operator allows to apply this operation to all the elements of a vector. If we wanted to add \\(2\\) to all the elements of the y vector, we should have written y .+= 2.\nThe last function size() is useful to get more dimension of the array we consider. In our case, it yields (100,) because it is a \\(100\\) rows vector. We would get the same if we did size(y).\n\nNow, let us plot the data we just created :\n\nplot(\n    scatter(x,y, label = \"data\"),\n    title = \"Generating Random Data\",\n    ylabel = \"Random variable\",\n    xlabel = \"x\",\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe function plot() in Julia comes from the Plots package. It is the default plotting function, with the gr backend by default (we will get to that later on). It contains several elements :\n\nThe function scatter() allows to plot a scatterplot, i.e. independent points that are not linked by a line. If we had not indicated the scatter() function, it would have plotted a line between all the points.\nThe label value is the one that gets displayed within the box. Specifying “data” allows to avoid the “y1” default value.\ntitle, ylabel and xlabel are pretty straightforward to understand.\n\nIt is now time to run a simple linear regression. Two simple ways to run such a model are :\n\nUsing the GLM package,\nUsing the built-in matrix computation function of Julia.\n\n\nGLM package\nFirst, with the GLM package :\n\nmodel = lm(@formula(y ~ x), (;y, x))\n\nStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int32}}}}, Matrix{Float64}}\n\ny ~ 1 + x\n\nCoefficients:\n──────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error     t  Pr(&gt;|t|)   Lower 95%  Upper 95%\n──────────────────────────────────────────────────────────────────────────\n(Intercept)  0.00995436   0.03272    0.30    0.7616  -0.0549775  0.0748862\nx            0.468727     0.0565302  8.29    &lt;1e-12   0.356545   0.58091\n──────────────────────────────────────────────────────────────────────────\n\n\nNow, if we want to plot our model with the data, we can run :\n\ncoefs = GLM.coef(model)\nplot!((x) -&gt; coefs[1] + coefs[2] * x, label=\"model\", \n    title = \"Simple linear regression\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we want to include the equation of our linear model in the legend of the plot, we can use the LaTeXStrings.jl package :\n\nusing LaTeXStrings\nplot(title = \"Simple linear regression\", \n    scatter(x,y, label = false),\n    (x) -&gt; coefs[1] + coefs[2] * x, label=latexstring(\"y=$(coefs[1]) + $(coefs[2]) * x\"))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd if we want it to be outside the plot :\n\nplot!(legend=:outerbottom, legendcolumns=1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix computation\nSecond, with the built-in matrix computation function :\n\nX = [ones(length(x)) x] \n(X\\y)\n\n2-element Vector{Float64}:\n 0.00995436086366171\n 0.4687272109439466\n\n\nThe first line creates a matrix \\(X\\) such that \\(X\\in\\mathbb{R}^{100\\times 100}\\), with its first columns being only ones, and its second column being the vector of \\(x\\).\nWithout entering into the details, it does exactly what the OLS method does, but in a more rudimentary way, using the normal equation to find the OLS estimates.\n\n\nPerformance comparison\nWe see that both approaches yield the same result, but what are the differences between them ? Apart from the syntax, we could check the performance of each of them. In order for us to do that, we are going to use the @time function, which returns the time and space used by a chosen function.\n@time begin\n    vec_1 = ones(length(x))\n    X = transpose([transpose(vec_1);transpose(x)])\n    (X\\y)\nend\n@time begin \n    model = lm(@formula(y ~ x), (;x, y))\n    GLM.coef(model)[1:2]\nend\n\n\n\nBuilt-in matrix approach :\n\n\n  0.000070 seconds (30 allocations: 40.266 KiB)\n\n\n2-element Vector{Float64}:\n 0.00995436086366171\n 0.4687272109439466\n\n\n\n\nGLM package approach :\n\n\n  0.000120 seconds (146 allocations: 20.438 KiB)\n\n\n2-element Vector{Float64}:\n 0.009954360863661988\n 0.46872721094394604\n\n\n\n\n\nIf we compare the information returned by the @time function, we see that the matrix computation approach seems to be slightly faster. However, we have to take into account that the lm() function does not only compute the coefficients, but alswo other informations, that are here not displayed, such as the confidence interval, and the probability associated to the t-statistic. In this sense, this comparison does not make justice to the GLM package. We can however remember that if we only wanted the coefficients of such a model, we could prefer the matrix multiplication approach if we need time."
  },
  {
    "objectID": "posts/1_regressions_julia/index.html#multiple-linear-regression",
    "href": "posts/1_regressions_julia/index.html#multiple-linear-regression",
    "title": "Linear Regressions with Julia",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nHere, let us try to explain one continuous variable by multiple continuous variables.\nAgain, we first have to generate and plot the data :\n\n# Generating random data :\nx,y,w,z = (rand(100) for _ in 1:4)\n\n# Plotting the data :\nplot(scatter(x, y, z,\n    title = \"Static 3D plot\", \n    marker_z = w, label=\"data\"))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nRotatable plot\nNow, we could continue with the plot function of the default gr backend package of Plots, but to get rotable 3D plots, we can use the PlotlyJS package. Since Plot.jl integrates plotly, we could try just adding plotly() :\n\n# We switch from the gr() to the plotlyjs() backend within Plots :\nplotlyjs()\n# We plot :\nplot(scatter(x, y, z;\n        marker_z = w,\n        markersize = 2, \n        title = \"Rotatable 3D plot\",\n        label = \"data\", \n        xlabel = \"x\",\n        ylabel = \"y\", \n        zlabel = \"z\"))\n\n    \n    \n\n\nIt is now time for some model. Let us consider that the variable z can be explained linearly by the variables x and y, and that w does not provide supplementary information.\nWe are going to use the two methods we saw previously :\n# Using matrix computations :\n@time begin\n    X = [ones(length(x)) x y]\n    X\\z\nend\n# Using GLM : \n@time begin \n    model = lm(@formula(z ~ x + y), (;x, y, z))\n    coefs = GLM.coef(model)\n    coefs\nend\n\n\n\nBuilt-in matrix approach :\n\n\n  0.000045 seconds (33 allocations: 42.531 KiB)\n\n\n3-element Vector{Float64}:\n  0.36233333368806564\n -0.0017472521580554313\n  0.21145297793195228\n\n\n\n\nGLM package approach :\n\n\n  0.000265 seconds (205 allocations: 29.141 KiB)\n\n\n3-element Vector{Float64}:\n  0.362333333688066\n -0.0017472521580556221\n  0.2114529779319519\n\n\n\n\n\n\nAs before, both results are approximatively the same, with a small advantage for the matrix computation approach in performance terms.\n\n\n\n\n\nPlotting a multinomial regression\nNow let’s try to plot the plane of this regression :\n\nlinear_model(x,y) = coefs[1] .+ coefs[2] * x .+ coefs[3] * y\nplot(x,y,linear_model,\n    st=:surface,\n    title = \"Plane of a two dimensional linear regression\",\n    label=\"model\",\n    xlabel =\"x\",\n    ylabel = \"y\",\n    zlabel = \"z\")\n\n    \n    \n\n\nWhile I did not manage to plot simulatneously the points and the surface on the plot, it seemed a satisfactory result for the moment."
  },
  {
    "objectID": "posts/purpose_statement/index.html",
    "href": "posts/purpose_statement/index.html",
    "title": "Purpose statement",
    "section": "",
    "text": "Hello, I am Paulo Gugelmo Cavalheiro Dias, currently a graduate level economics students, and this is the first post of my blog, in which I would like to write its purpose statement.\nI want this blog to be a way of sharing my progress in the topics I am interested in, i.e. economics and related subjects, such as programming for social sciences, environmental economics, etc. To do so, I will try to write regular reports on my work in social science, about my classes, readings and other materials."
  }
]